{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR6XeEffyZ4Y"
   },
   "source": [
    "#### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPfGPcoiuhGI",
    "outputId": "1f1534eb-9f6a-497a-d912-af1b56365c33"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2-cp310-cp310-manylinux2014_x86_64.whl (98.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting optuna\n",
      "  Downloading optuna-3.1.1-py3-none-any.whl (365 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m365.7/365.7 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
      "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
      "Collecting alembic>=1.5.0 (from optuna)\n",
      "  Downloading alembic-1.11.1-py3-none-any.whl (224 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cmaes>=0.9.1 (from optuna)\n",
      "  Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "Collecting colorlog (from optuna)\n",
      "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (23.1)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.10)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0)\n",
      "Collecting Mako (from alembic>=1.5.0->optuna)\n",
      "  Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (2.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.39.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (2.1.2)\n",
      "Installing collected packages: Mako, colorlog, cmaes, alembic, optuna, catboost\n",
      "Successfully installed Mako-1.2.4 alembic-1.11.1 catboost-1.2 cmaes-0.9.1 colorlog-6.7.0 optuna-3.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost optuna\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost as ct\n",
    "from sklearn.metrics import log_loss, confusion_matrix, roc_curve, roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import optuna\n",
    "import os\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dajqRpkgyieV"
   },
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jyTve-9u6u7",
    "outputId": "f198dc6f-3a55-44b3-fcac-de00644f3a04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "train = pd.read_csv('/content/drive/MyDrive/icr-identify-age-related-conditions/train.csv')\n",
    "test = pd.read_csv('/content/drive/MyDrive/icr-identify-age-related-conditions/test.csv')\n",
    "greeks = pd.read_csv('/content/drive/MyDrive/icr-identify-age-related-conditions/greeks.csv')\n",
    "sample_submission = pd.read_csv('/content/drive/MyDrive/icr-identify-age-related-conditions/sample_submission.csv')\n",
    "\n",
    "##---- Copy from here\n",
    "\n",
    "df = pd.merge(train, greeks, how='left', on='Id')\n",
    "def encode(dataframe):\n",
    "    le = LabelEncoder()\n",
    "    obj = list(dataframe.loc[:, dataframe.dtypes == 'object'].columns)\n",
    "    for i in obj:\n",
    "        if i not in ['id', 'Epsilon']:\n",
    "            dataframe[i] = le.fit_transform(dataframe[i])\n",
    "    return dataframe\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "\n",
    "features = ['AB', 'AF', 'AH', 'AM', 'AR', 'AX', 'AY', 'AZ', 'BC', 'BD ', 'BN',\n",
    "       'BP', 'BQ', 'BR', 'BZ', 'CB', 'CC', 'CD ', 'CF', 'CH', 'CL', 'CR', 'CS',\n",
    "       'CU', 'CW ', 'DA', 'DE', 'DF', 'DH', 'DI', 'DL', 'DN', 'DU', 'DV', 'DY',\n",
    "       'EB', 'EE', 'EG', 'EH', 'EJ', 'EL', 'EP', 'EU', 'FC', 'FD ', 'FE', 'FI',\n",
    "       'FL', 'FR', 'FS', 'GB', 'GE', 'GF', 'GH', 'GI', 'GL']\n",
    "\n",
    "df = encode(df)  \n",
    "test = encode(test)\n",
    "\n",
    "df[features] = imputer.fit_transform(df[features])\n",
    "test[features] = imputer.fit_transform(test[features])\n",
    "\n",
    "target = 'Class'\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Assuming X and y are your features and labels\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1Zt-QasyXr9"
   },
   "source": [
    "#### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Pe68yo5_vfgB"
   },
   "outputs": [],
   "source": [
    "def balanced_log_loss(y_true, y_pred, class_weights):\n",
    "    epsilon = 1e-15\n",
    "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
    "    w0 = 1/class_weights[0]\n",
    "    w1 = 1/class_weights[1]\n",
    "    loss = -2*(w0 * y_true * np.log(y_pred[:,1]) + w1 * (1 - y_true) * np.log(y_pred[:,0]))/(w0+w1)\n",
    "    return loss.mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B4RqyjsFy9xz"
   },
   "source": [
    "#### Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z6m1O1aWzBKi"
   },
   "outputs": [],
   "source": [
    "best_params = {'iterations': 212,\n",
    " 'depth': 4,\n",
    " 'learning_rate': 0.02995163795315085,\n",
    " 'random_strength': 0,\n",
    " 'bagging_temperature': 0.010387485768987258,\n",
    " 'od_type': 'Iter',\n",
    " 'od_wait': 37}\n",
    "class_counts = y.value_counts()\n",
    "class_weights = {class_counts.index[0]: class_counts[1] / (class_counts[1]+class_counts[0]),\n",
    "                     class_counts.index[1]: class_counts[0] / (class_counts[1]+class_counts[0])}\n",
    "final_model = CatBoostClassifier(**best_params, loss_function='Logloss', eval_metric='Logloss',task_type = 'GPU', class_weights=class_weights)\n",
    "final_model.fit(X, y,verbose = 0) # Train on the full data\n",
    "prediction = final_model.predict_proba(test[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yz-CYxmezCWC",
    "outputId": "1056a34a-2553-4c62-a90a-3eb41595bd7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Log Loss on test data across 10 folds:  0.18127967275749446\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "# define a StratifiedKFold object\n",
    "strat_kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=int(random.random()*1000))\n",
    "\n",
    "# list to store log loss for each fold\n",
    "log_loss_scores = []\n",
    "\n",
    "for train_index, test_index in strat_kfold.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model = CatBoostClassifier(**best_params, loss_function='Logloss', eval_metric='Logloss', class_weights=class_weights)\n",
    "    model.fit(X_train, y_train, verbose=0)\n",
    "    \n",
    "    y_pred = model.predict_proba(X_test)\n",
    "    fold_log_loss = balanced_log_loss(y_test, y_pred,class_weights)\n",
    "    log_loss_scores.append(fold_log_loss)\n",
    "    \n",
    "# print the mean log loss across all folds\n",
    "print(\"Mean Log Loss on test data across 10 folds: \", np.mean(log_loss_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XXKrRJo2ctoN",
    "outputId": "f13c4c6b-3de9-47ba-f4aa-a94dd7a711a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1802107408611545,\n",
       " 0.14310649327564143,\n",
       " 0.26260660254315477,\n",
       " 0.19017781141942705,\n",
       " 0.13029671568809467]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JrUNAq3Ps4mx",
    "outputId": "9a0ad605-41d9-456e-9b41-0bd9fed898ca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-26 17:36:27,286]\u001b[0m A new study created in memory with name: no-name-b1274099-032d-4b5c-95f7-86ae41916c01\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 17:38:25,348]\u001b[0m Trial 0 finished with value: 0.2128080146597731 and parameters: {'iterations': 296, 'depth': 13, 'learning_rate': 0.02250166425923213, 'random_strength': 2, 'bagging_temperature': 19.944323466207972, 'od_type': 'Iter', 'od_wait': 16}. Best is trial 0 with value: 0.2128080146597731.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 17:40:14,100]\u001b[0m Trial 1 finished with value: 0.22725899438935554 and parameters: {'iterations': 262, 'depth': 11, 'learning_rate': 0.024281461411614327, 'random_strength': 65, 'bagging_temperature': 0.02872373924991248, 'od_type': 'Iter', 'od_wait': 49}. Best is trial 0 with value: 0.2128080146597731.\u001b[0m\n",
      "\u001b[32m[I 2023-05-26 17:41:24,669]\u001b[0m Trial 2 finished with value: 0.19994706870937054 and parameters: {'iterations': 271, 'depth': 8, 'learning_rate': 0.024675582577956198, 'random_strength': 15, 'bagging_temperature': 2.9730331991436594, 'od_type': 'Iter', 'od_wait': 17}. Best is trial 2 with value: 0.19994706870937054.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import log_loss\n",
    "import optuna\n",
    "\n",
    "def objective(trial):\n",
    "    # Parameters to tune\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 250,300),\n",
    "        'depth': trial.suggest_int('depth', 8,14),\n",
    "        'learning_rate': trial.suggest_uniform('learning_rate', 0.02, 0.03),\n",
    "        'random_strength': trial.suggest_int('random_strength', 0, 100),\n",
    "        'bagging_temperature': trial.suggest_loguniform('bagging_temperature', 0.01, 50.00),\n",
    "        'od_type': trial.suggest_categorical('od_type', ['IncToDec', 'Iter']),\n",
    "        'od_wait': trial.suggest_int('od_wait', 10, 50)\n",
    "    }\n",
    "    \n",
    "    # Compute class weights\n",
    "    class_counts = y.value_counts()\n",
    "    class_weights = {class_counts.index[0]: class_counts[1] / (class_counts[1]+class_counts[0]),\n",
    "                     class_counts.index[1]: class_counts[0] / (class_counts[1]+class_counts[0])}\n",
    "\n",
    "    n_splits = 5\n",
    "    n_repeats = 5  # Number of times cross-validator needs to be repeated.\n",
    "    rskf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    log_loss_scores = []\n",
    "    for train_index, valid_index in rskf.split(X, y):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        \n",
    "        model = CatBoostClassifier(**params, loss_function='Logloss', eval_metric='Logloss', task_type='GPU', class_weights=class_weights)\n",
    "        model.fit(X_train, y_train, eval_set=[(X_valid, y_valid)], early_stopping_rounds=100, verbose=False)\n",
    "        \n",
    "        pred_valid = model.predict_proba(X_valid)\n",
    "        log_loss_scores.append(balanced_log_loss(y_valid, pred_valid,class_weights))\n",
    "    \n",
    "    return np.mean(log_loss_scores)\n",
    "\n",
    "# Create the study and run optimization\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJhu4dP_iODo"
   },
   "outputs": [],
   "source": [
    "# Compute class weights\n",
    "import random\n",
    "class_counts = y.value_counts()\n",
    "class_weights = {class_counts.index[0]: class_counts[1] / (class_counts[1]+class_counts[0]),\n",
    "                     class_counts.index[1]: class_counts[0] / (class_counts[1]+class_counts[0])}\n",
    "\n",
    "X_t, X_test, y_t, y_test = train_test_split(X, y, test_size=0.5, random_state=int(random.random()*1000))\n",
    "best_params = study.best_params\n",
    "model = CatBoostClassifier(**best_params, loss_function='Logloss', eval_metric='Logloss', class_weights=class_weights)\n",
    "model.fit(X_t, y_t, verbose=0)\n",
    "y_pred = model.predict_proba(X_test)\n",
    "balanced_log_loss(y_test, y_pred,class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAHWuaHSzsO9"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
